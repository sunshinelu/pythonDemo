{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "参考链接:\n",
    "\n",
    "<http://www.52nlp.cn/%E5%A6%82%E4%BD%95%E8%AE%A1%E7%AE%97%E4%B8%A4%E4%B8%AA%E6%96%87%E6%A1%A3%E7%9A%84%E7%9B%B8%E4%BC%BC%E5%BA%A6%E4%BA%8C>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"Shipment of gold damaged in a fire\",\n",
    "    \"Delivery of silver arrived in a silver truck\",\n",
    "    \"Shipment of gold arrived in a truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['shipment', 'of', 'gold', 'damaged', 'in', 'a', 'fire'], ['delivery', 'of', 'silver', 'arrived', 'in', 'a', 'silver', 'truck'], ['shipment', 'of', 'gold', 'arrived', 'in', 'a', 'truck']]\n"
     ]
    }
   ],
   "source": [
    "texts = [[word for word in document.lower().split()] for document in documents]\n",
    "print texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:36:03,940 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:36:03,958 : INFO : built Dictionary(11 unique tokens: [u'a', u'damaged', u'gold', u'fire', u'of']...) from 3 documents (total 22 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(11 unique tokens: [u'a', u'damaged', u'gold', u'fire', u'of']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "print dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'a': 0, u'damaged': 1, u'gold': 2, u'fire': 3, u'of': 4, u'delivery': 7, u'truck': 8, u'shipment': 5, u'in': 6, u'arrived': 9, u'silver': 10}\n"
     ]
    }
   ],
   "source": [
    "print dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)], [(0, 1), (4, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2)], [(0, 1), (2, 1), (4, 1), (5, 1), (6, 1), (8, 1), (9, 1)]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "print corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:37:51,631 : INFO : collecting document frequencies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:37:51,634 : INFO : PROGRESS: processing document #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:37:51,637 : INFO : calculating IDF weights for 3 documents and 10 features (21 matrix non-zeros)\n"
     ]
    }
   ],
   "source": [
    "tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.6633689723434505), (2, 0.2448297500958463), (3, 0.6633689723434505), (5, 0.2448297500958463)]\n[(7, 0.4355066251613605), (8, 0.16073253746956623), (9, 0.16073253746956623), (10, 0.871013250322721)]\n[(2, 0.5), (5, 0.5), (8, 0.5), (9, 0.5)]\n"
     ]
    }
   ],
   "source": [
    "corpus_tfidf = tfidf[corpus]\n",
    "for doc in corpus_tfidf:\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 3, 1: 1, 2: 2, 3: 1, 4: 3, 5: 2, 6: 3, 7: 1, 8: 2, 9: 2, 10: 1}\n"
     ]
    }
   ],
   "source": [
    "print tfidf.dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.0, 1: 1.5849625007211563, 2: 0.5849625007211562, 3: 1.5849625007211563, 4: 0.0, 5: 0.5849625007211562, 6: 0.0, 7: 1.5849625007211563, 8: 0.5849625007211562, 9: 0.5849625007211562, 10: 1.5849625007211563}\n"
     ]
    }
   ],
   "source": [
    "print tfidf.idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:43:11,744 : INFO : using serial LSI version on this node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:43:11,747 : INFO : updating model with new documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:43:11,750 : INFO : preparing a new chunk of documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:43:11,754 : INFO : using 100 extra samples and 2 power iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:43:11,756 : INFO : 1st phase: constructing (11, 102) action matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:43:11,760 : INFO : orthonormalizing (11, 102) action matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:43:11,791 : INFO : 2nd phase: running dense svd on (11, 3) matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:43:11,805 : INFO : computing the final decomposition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:43:11,808 : INFO : keeping 2 factors (discarding 23.571% of energy spectrum)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:43:11,812 : INFO : processed documents up to #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:43:11,815 : INFO : topic #0(1.137): 0.438*\"gold\" + 0.438*\"shipment\" + 0.366*\"truck\" + 0.366*\"arrived\" + 0.345*\"damaged\" + 0.345*\"fire\" + 0.297*\"silver\" + 0.149*\"delivery\" + 0.000*\"a\" + -0.000*\"in\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:43:11,819 : INFO : topic #1(1.000): 0.728*\"silver\" + -0.364*\"damaged\" + -0.364*\"fire\" + 0.364*\"delivery\" + 0.134*\"truck\" + 0.134*\"arrived\" + -0.134*\"gold\" + -0.134*\"shipment\" + 0.000*\"a\" + -0.000*\"of\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:43:11,823 : INFO : topic #0(1.137): 0.438*\"gold\" + 0.438*\"shipment\" + 0.366*\"truck\" + 0.366*\"arrived\" + 0.345*\"damaged\" + 0.345*\"fire\" + 0.297*\"silver\" + 0.149*\"delivery\" + 0.000*\"a\" + -0.000*\"in\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:43:11,825 : INFO : topic #1(1.000): 0.728*\"silver\" + -0.364*\"damaged\" + -0.364*\"fire\" + 0.364*\"delivery\" + 0.134*\"truck\" + 0.134*\"arrived\" + -0.134*\"gold\" + -0.134*\"shipment\" + 0.000*\"a\" + -0.000*\"of\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n  u'0.438*\"gold\" + 0.438*\"shipment\" + 0.366*\"truck\" + 0.366*\"arrived\" + 0.345*\"damaged\" + 0.345*\"fire\" + 0.297*\"silver\" + 0.149*\"delivery\" + 0.000*\"a\" + -0.000*\"in\"'),\n (1,\n  u'0.728*\"silver\" + -0.364*\"damaged\" + -0.364*\"fire\" + 0.364*\"delivery\" + 0.134*\"truck\" + 0.134*\"arrived\" + -0.134*\"gold\" + -0.134*\"shipment\" + 0.000*\"a\" + -0.000*\"of\"')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2)\n",
    "lsi.print_topics(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.67211468809878627), (1, -0.54880682119355995)]\n[(0, 0.44124825208697765), (1, 0.83594920480339041)]\n[(0, 0.80401378963792725)]\n"
     ]
    }
   ],
   "source": [
    "corpus_lsi = lsi[corpus_tfidf]\n",
    "for doc in corpus_lsi:\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:46:15,994 : INFO : using symmetric alpha at 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:46:15,998 : INFO : using symmetric eta at 0.0909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:46:15,999 : INFO : using serial LDA version on this node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:46:16,003 : INFO : running online (single-pass) LDA training, 2 topics, 1 passes over the supplied corpus of 3 documents, updating model once every 3 documents, evaluating perplexity every 3 documents, iterating 50x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:46:16,004 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:46:16,017 : INFO : -4.130 per-word bound, 17.5 perplexity estimate based on a held-out corpus of 3 documents with 5 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:46:16,018 : INFO : PROGRESS: pass 0, at document #3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:46:16,030 : INFO : topic #0 (0.500): 0.123*\"silver\" + 0.110*\"gold\" + 0.105*\"truck\" + 0.104*\"shipment\" + 0.102*\"damaged\" + 0.100*\"fire\" + 0.099*\"arrived\" + 0.086*\"delivery\" + 0.057*\"a\" + 0.057*\"of\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:46:16,032 : INFO : topic #1 (0.500): 0.109*\"shipment\" + 0.103*\"arrived\" + 0.103*\"silver\" + 0.102*\"gold\" + 0.102*\"fire\" + 0.100*\"damaged\" + 0.097*\"truck\" + 0.088*\"delivery\" + 0.065*\"a\" + 0.065*\"of\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:46:16,034 : INFO : topic diff=0.391449, rho=1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:46:16,037 : INFO : topic #0 (0.500): 0.123*\"silver\" + 0.110*\"gold\" + 0.105*\"truck\" + 0.104*\"shipment\" + 0.102*\"damaged\" + 0.100*\"fire\" + 0.099*\"arrived\" + 0.086*\"delivery\" + 0.057*\"a\" + 0.057*\"of\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:46:16,041 : INFO : topic #1 (0.500): 0.109*\"shipment\" + 0.103*\"arrived\" + 0.103*\"silver\" + 0.102*\"gold\" + 0.102*\"fire\" + 0.100*\"damaged\" + 0.097*\"truck\" + 0.088*\"delivery\" + 0.065*\"a\" + 0.065*\"of\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n  u'0.123*\"silver\" + 0.110*\"gold\" + 0.105*\"truck\" + 0.104*\"shipment\" + 0.102*\"damaged\" + 0.100*\"fire\" + 0.099*\"arrived\" + 0.086*\"delivery\" + 0.057*\"a\" + 0.057*\"of\"'),\n (1,\n  u'0.109*\"shipment\" + 0.103*\"arrived\" + 0.103*\"silver\" + 0.102*\"gold\" + 0.102*\"fire\" + 0.100*\"damaged\" + 0.097*\"truck\" + 0.088*\"delivery\" + 0.065*\"a\" + 0.065*\"of\"')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus_tfidf, id2word=dictionary, num_topics=2)\n",
    "lda.print_topics(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:46:53,300 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-03 16:46:53,303 : INFO : creating matrix with 3 documents and 2 features\n"
     ]
    }
   ],
   "source": [
    "index = similarities.MatrixSimilarity(lsi[corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 1), (8, 1), (10, 1)]\n"
     ]
    }
   ],
   "source": [
    "query = \"gold silver truck\"\n",
    "query_bow = dictionary.doc2bow(query.lower().split())\n",
    "print query_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1.1012835748628476), (1, 0.72812283398049615)]\n"
     ]
    }
   ],
   "source": [
    "query_lsi = lsi[query_bow]\n",
    "print query_lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.40757114), (1, 0.93163693), (2, 0.83416492)]\n"
     ]
    }
   ],
   "source": [
    "sims = index[query_lsi]\n",
    "print list(enumerate(sims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.93163693), (2, 0.83416492), (0, 0.40757114)]\n"
     ]
    }
   ],
   "source": [
    "sort_sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "print sort_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}